{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"detect_parking_space.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"cell_type":"code","metadata":{"id":"fic18l2RwUct","colab_type":"code","colab":{}},"source":["!pip install fastai\n","%pylab notebook"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmAfxBC3u7j3","colab_type":"code","colab":{}},"source":["!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aDECZVeby7M","colab_type":"code","colab":{}},"source":["!pip install pyyaml"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRRq28TjdQ-h","colab_type":"code","colab":{}},"source":["import cv2\n","import os\n","import yaml\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","%matplotlib inline\n","import cv2\n","import io\n","import base64\n","from IPython.display import HTML\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8SGwUvEdSYQ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7-_WZ_cdhaT","colab_type":"code","colab":{}},"source":["os.chdir('/content/drive/My Drive/PCD/DetectParking/datasets')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-f14iJzVcuVa","colab_type":"code","colab":{}},"source":["fn = r\"/content/drive/My Drive/PCD/DetectParking/datasets/mobilfinal.mp4\"\n","fn_yaml = r\"/content/drive/My Drive/PCD/DetectParking/datasets/parking2.yml\"\n","fn_out = r\"/content/drive/My Drive/PCD/DetectParking/datasets/output.avi\"\n","config = {'save_video': False,\n","          'text_overlay': True,\n","          'parking_overlay': True,\n","          'parking_id_overlay': False,\n","          'parking_detection': True,\n","          'min_area_motion_contour': 60,\n","          'park_sec_to_wait': 3,\n","          'start_frame': 0} #35000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6Vn93rZiEk6","colab_type":"text"},"source":["Set capture device or file"]},{"cell_type":"code","metadata":{"id":"jPKGjtJfgbkW","colab_type":"code","colab":{}},"source":["cap = cv2.VideoCapture(fn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ALJIAQOGiLqc","colab_type":"text"},"source":["Print cap.get(5)"]},{"cell_type":"code","metadata":{"id":"AYHxY_GpiKGw","colab_type":"code","colab":{}},"source":["video_info = {'fps':    cap.get(cv2.CAP_PROP_FPS),\n","              'width':  int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n","              'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n","              'fourcc': cap.get(cv2.CAP_PROP_FOURCC),\n","              'num_of_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT))}\n","cap.set(cv2.CAP_PROP_POS_FRAMES, config['start_frame']) # jump to frame"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gp6R_yX0iXLD","colab_type":"text"},"source":["Define the codec and create VideoWriter object"]},{"cell_type":"code","metadata":{"id":"1BP2QrQViTdU","colab_type":"code","colab":{}},"source":["if config['save_video']:\n","    fourcc = cv2.VideoWriter_fourcc('D','I','V','X')# options: ('P','I','M','1'), ('D','I','V','X'), ('M','J','P','G'), ('X','V','I','D')\n","    out = cv2.VideoWriter(fn_out, -1, 25.0, #video_info['fps'], \n","                          (video_info['width'], video_info['height']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNnsnlYSihtc","colab_type":"text"},"source":["Read YAML data (parking space polygons)"]},{"cell_type":"code","metadata":{"id":"f79Mf9Sj55Ko","colab_type":"code","colab":{}},"source":["# Read YAML data (parking space polygons)\n","with open(fn_yaml, 'r') as stream:\n","    parking_data = yaml.load(stream)\n","parking_contours = []\n","parking_bounding_rects = []\n","parking_mask = []\n","for park in parking_data:\n","    points = np.array(park['points'])\n","    rect = cv2.boundingRect(points)\n","    points_shifted = points.copy()\n","    points_shifted[:,0] = points[:,0] - rect[0] # shift contour to roi\n","    points_shifted[:,1] = points[:,1] - rect[1]\n","    parking_contours.append(points)\n","    parking_bounding_rects.append(rect)\n","    mask = cv2.drawContours(np.zeros((rect[3], rect[2]), dtype=np.uint8), [points_shifted], contourIdx=-1,\n","                            color=255, thickness=-1, lineType=cv2.LINE_8)\n","    mask = mask==255\n","    parking_mask.append(mask)\n","\n","parking_status = [False]*len(parking_data)\n","parking_buffer = [None]*len(parking_data)\n","\n","\n","while(cap.isOpened()):   \n","    spot = 0\n","    occupied = 0 \n","    # Read frame-by-frame    \n","    video_cur_pos = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0 # Current position of the video file in seconds\n","    video_cur_frame = cap.get(cv2.CAP_PROP_POS_FRAMES) # Index of the frame to be decoded/captured next\n","    ret, frame = cap.read()    \n","    if ret == False:\n","        print(\"Capture Error\")\n","        break\n","    \n","    # frame_gray = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2GRAY)\n","    # Background Subtraction\n","    frame_blur = cv2.GaussianBlur(frame.copy(), (5,5), 3)\n","    frame_gray = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2GRAY)\n","    frame_out = frame.copy()\n","    \n","\n","    if config['parking_detection']:        \n","        for ind, park in enumerate(parking_data):\n","            points = np.array(park['points'])\n","            rect = parking_bounding_rects[ind]\n","            roi_gray = frame_gray[rect[1]:(rect[1]+rect[3]), rect[0]:(rect[0]+rect[2])] # crop roi for faster calculation   \n","            # print np.std(roi_gray)\n","\n","            points[:,0] = points[:,0] - rect[0] # shift contour to roi\n","            points[:,1] = points[:,1] - rect[1]\n","            # print np.std(roi_gray), np.mean(roi_gray)\n","            status = np.std(roi_gray) < 22 and np.mean(roi_gray) > 53\n","            # If detected a change in parking status, save the current time\n","            if status != parking_status[ind] and parking_buffer[ind]==None:\n","                parking_buffer[ind] = video_cur_pos\n","            # If status is still different than the one saved and counter is open\n","            elif status != parking_status[ind] and parking_buffer[ind]!=None:\n","                if video_cur_pos - parking_buffer[ind] > config['park_sec_to_wait']:\n","                    parking_status[ind] = status\n","                    parking_buffer[ind] = None\n","            # If status is still same and counter is open                    \n","            elif status == parking_status[ind] and parking_buffer[ind]!=None:\n","                #if video_cur_pos - parking_buffer[ind] > config['park_sec_to_wait']:\n","                parking_buffer[ind] = None                    \n","            # print(parking_status)\n","   \n","    if config['parking_overlay']:                    \n","        for ind, park in enumerate(parking_data):\n","            points = np.array(park['points'])\n","            if parking_status[ind]: \n","                color = (0,255,0)\n","                spot = spot+1\n","            else: \n","                color = (0,0,255)\n","                occupied = occupied+1\n","            cv2.drawContours(frame_out, [points], contourIdx=-1,\n","                             color=color, thickness=2, lineType=cv2.LINE_8)            \n","            moments = cv2.moments(points)        \n","            centroid = (int(moments['m10']/moments['m00'])-3, int(moments['m01']/moments['m00'])+3)\n","            cv2.putText(frame_out, str(park['id']), (centroid[0]+1, centroid[1]+1), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, cv2.LINE_AA)\n","            cv2.putText(frame_out, str(park['id']), (centroid[0]-1, centroid[1]-1), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, cv2.LINE_AA)\n","            cv2.putText(frame_out, str(park['id']), (centroid[0]+1, centroid[1]-1), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, cv2.LINE_AA)\n","            cv2.putText(frame_out, str(park['id']), (centroid[0]-1, centroid[1]+1), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, cv2.LINE_AA)\n","            cv2.putText(frame_out, str(park['id']), centroid, cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 1, cv2.LINE_AA)\n","            # print 'occupied: ', occupied\n","            # print 'spot: ', spot\n","\n","    # Draw Overlay\n","    if config['text_overlay']:\n","        cv2.rectangle(frame_out, (1, 5), (280, 90),(255,255,255), 85) \n","        str_on_frame = \"Frames: %d/%d\" % (video_cur_frame, video_info['num_of_frames'])\n","        cv2.putText(frame_out, str_on_frame, (5,30), cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n","                    0.7, (0,128,255), 2, cv2.LINE_AA)\n","        str_on_frame = \"Spot: %d Occupied: %d\" % (spot, occupied)\n","        cv2.putText(frame_out, str_on_frame, (5,90), cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n","                            0.7, (0,128,255), 2, cv2.LINE_AA)\n","\n","            \n","    # write the output frame\n","    if config['save_video']:\n","        if video_cur_frame % 35 == 0: # take every 30 frames\n","            out.write(frame_out)    \n","    \n","    # Display video\n","    cv2_imshow(frame_out)\n","    cv2.waitKey(40)\n","    # cv2.imshow('background mask', bw)\n","    k = cv2.waitKey(1)\n","    if k == ord('q'):\n","        break\n","    elif k == ord('c'):\n","        cv2.imwrite('frame%d.jpg' % video_cur_frame, frame_out)\n","    elif k == ord('j'):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, video_cur_frame+1000) # jump to frame\n","        plt.imshow(image)\n","plt.show()\n","\n","cap.release()\n","if config['save_video']: out.release()\n","cv2.destroyAllWindows()    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDVrOIaEXOeZ","colab_type":"code","colab":{}},"source":["from google.colab.patches import cv2_imshow\n","%matplotlib inline\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBEnqeDaXOdi","colab_type":"code","colab":{}},"source":["!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png\n","import cv2\n","img = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)\n","cv2_imshow(img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHJ2ynCx8jrp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}